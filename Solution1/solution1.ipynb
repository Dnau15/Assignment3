{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8244071,"sourceType":"datasetVersion","datasetId":4890782}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install razdel\n# This is rule-based system for Russian sentence and word tokenization.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T16:24:22.247963Z","iopub.execute_input":"2024-04-28T16:24:22.248443Z","iopub.status.idle":"2024-04-28T16:24:37.117980Z","shell.execute_reply.started":"2024-04-28T16:24:22.248391Z","shell.execute_reply":"2024-04-28T16:24:37.116716Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: razdel in /opt/conda/lib/python3.10/site-packages (0.5.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom collections import defaultdict, Counter\nimport json\nfrom razdel import tokenize\nfrom copy import deepcopy\n\ntrain_data = pd.read_json('/kaggle/input/assignment3/train.jsonl', lines=True)\ndev = pd.read_json('/kaggle/input/assignment3/dev.jsonl', lines=True)\ntest = pd.read_json('/kaggle/input/assignment3/test.jsonl', lines=True)\n\n# columns renaming\ndev.rename(columns={\"senences\": \"sentences\"}, inplace=True)\ntest.rename(columns={\"senences\": \"sentences\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:24:37.120239Z","iopub.execute_input":"2024-04-28T16:24:37.120637Z","iopub.status.idle":"2024-04-28T16:24:37.214799Z","shell.execute_reply.started":"2024-04-28T16:24:37.120601Z","shell.execute_reply":"2024-04-28T16:24:37.213443Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\ndef train(train_data):\n    my_dict = dict()\n\n    for _, row in train_data.iterrows():\n        for start, end, label in row['ners']:\n            token = row['sentences'][start:end+1]\n\n            if token not in my_dict:\n                my_dict[token] = Counter()\n\n            my_dict[token][label] = my_dict[token].get(label, 0) + 1\n    return my_dict","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:24:37.216430Z","iopub.execute_input":"2024-04-28T16:24:37.216844Z","iopub.status.idle":"2024-04-28T16:24:37.225043Z","shell.execute_reply.started":"2024-04-28T16:24:37.216810Z","shell.execute_reply":"2024-04-28T16:24:37.223633Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dict = train(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:24:37.227798Z","iopub.execute_input":"2024-04-28T16:24:37.228185Z","iopub.status.idle":"2024-04-28T16:24:37.652726Z","shell.execute_reply.started":"2024-04-28T16:24:37.228152Z","shell.execute_reply":"2024-04-28T16:24:37.651599Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def predict(row):\n    \"\"\"\n    This function makes prediction\n    \"\"\"\n    # Tokenize sentence\n    tokens = list(tokenize(row['sentences']))\n    ners = []\n    # Each \"token\" contains start index, end index and token\n    for token in tokens:\n        start, end, text = token\n        end -= 1\n\n        # If we found token in dict then we should find Label of this token\n        if text in train_dict:\n            ners.append([start, end, train_dict[text].most_common(1)[0][0]])\n    return ners","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:25:26.060241Z","iopub.execute_input":"2024-04-28T16:25:26.060653Z","iopub.status.idle":"2024-04-28T16:25:26.071450Z","shell.execute_reply.started":"2024-04-28T16:25:26.060623Z","shell.execute_reply":"2024-04-28T16:25:26.070379Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test.apply(predict, axis=1)\ntest.drop(['sentences'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:25:27.520326Z","iopub.execute_input":"2024-04-28T16:25:27.521321Z","iopub.status.idle":"2024-04-28T16:25:27.767235Z","shell.execute_reply.started":"2024-04-28T16:25:27.521283Z","shell.execute_reply":"2024-04-28T16:25:27.766084Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Save the results\noutput_path = 'test.jsonl'\nwith open(output_path, \"w\") as f:\n    f.write(test.to_json(orient='records', lines=True, force_ascii=False))\n!zip test test.jsonl","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:25:28.764523Z","iopub.execute_input":"2024-04-28T16:25:28.765714Z","iopub.status.idle":"2024-04-28T16:25:29.886071Z","shell.execute_reply.started":"2024-04-28T16:25:28.765635Z","shell.execute_reply":"2024-04-28T16:25:29.884486Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"  adding: test.jsonl (deflated 82%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}